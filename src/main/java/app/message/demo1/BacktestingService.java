package app.message.demo1;

import java.util.ArrayList;
import java.util.Arrays;

import org.springframework.beans.factory.annotation.Autowired;
import org.springframework.stereotype.Service;
import org.apache.commons.logging.Log;
import org.apache.commons.logging.LogFactory;
import org.apache.commons.math3.linear.MatrixUtils;
import org.apache.commons.math3.linear.RealMatrix;
import org.apache.commons.math3.linear.RealVector;
import org.apache.spark.sql.*;
import org.apache.spark.sql.expressions.Window;
import org.apache.spark.sql.types.DataTypes;
import org.apache.spark.sql.types.StructField;
import org.apache.spark.sql.types.StructType;

// import java.awt.List;
import java.awt.image.BufferedImage;
import java.io.ByteArrayOutputStream;
import java.util.Base64;
import java.util.HashMap;
import java.util.List;
import java.util.Map;

import javax.imageio.ImageIO;
import java.util.Random;
import java.util.stream.Collectors;

import org.knowm.xchart.*;

@Service
public class BacktestingService {

    private final Log log = LogFactory.getLog(AuthController.class);

    private final SparkSession spark;
    
    @Autowired
    public BacktestingService(SparkSession spark) {
        this.spark = spark;
    }

    public String runMonteCarloSimulation(String jsonData) {
        // âœ… JSON ë°ì´í„° ë¡œë“œ (ticker: "AAPL", close: 170.0 í˜•ì‹)
        Dataset<Row> df = spark.read().json(spark.createDataset(Arrays.asList(jsonData), Encoders.STRING()));
    
        // âœ… ë‚ ì§œë³„ë¡œ í‹°ì»¤ë³„ ê°€ê²©ì„ ë³€í™˜ (pivot)
        // Step 1: Pivot the DataFrame
        Dataset<Row> pivotedDf = df.groupBy("time")  // Group by time
                                .pivot("ticker")  // Pivot by ticker
                                .agg(functions.first("tradePrice"));  // Use the first trade price for each ticker

        // Step 2: Extract ticker columns (excluding "time")
        String[] tickerColumns = pivotedDf.columns();
        List<String> tickers = Arrays.stream(tickerColumns)
                                    .filter(col -> !col.equals("time"))
                                    .collect(Collectors.toList());

        // Step 3: Create "prev" columns using lag function
        Dataset<Row> shiftedDf = pivotedDf;
        for (String ticker : tickers) {
            String prevTicker = "prev_" + ticker;
            shiftedDf = shiftedDf.withColumn(prevTicker, functions.lag(ticker, 1).over(Window.orderBy("time")));
        }

        // Step 4: Calculate daily returns
        Dataset<Row> dailyReturnsDf = shiftedDf;
        for (String ticker : tickers) {
            String dailyRet = "daily_ret_" + ticker;
            String prevTicker = "prev_" + ticker;
            dailyReturnsDf = dailyReturnsDf.withColumn(dailyRet, functions.expr("(" + ticker + " - " + prevTicker + ") / " + prevTicker));
        }

        // Step 5: Select only daily return columns
        List<String> dailyRetColumns = tickers.stream()
                                            .map(ticker -> "daily_ret_" + ticker)
                                            .collect(Collectors.toList());

        Dataset<Row> resultDf = dailyReturnsDf.selectExpr(dailyRetColumns.toArray(new String[0]));

        // Step 6: Remove rows with null values in the first daily return column
        Dataset<Row> nullRemovedResultDf = resultDf.filter(resultDf.col(dailyRetColumns.get(0)).isNotNull());

    
        // ë°ì´í„°í”„ë ˆì„ì˜ ëª¨ë“  ì»¬ëŸ¼ ì¤‘ì—ì„œ "daily_ret"ì´ í¬í•¨ëœ ì»¬ëŸ¼ëª…ë§Œ í•„í„°ë§
        String[] RetColumns = Arrays.stream(dailyReturnsDf.columns())
                .filter(colName -> colName.contains("daily_ret"))
                .toArray(String[]::new);

        // filteredDfëŠ” daily_ret ì»¬ëŸ¼ë§Œ í¬í•¨í•˜ëŠ” ë°ì´í„°í”„ë ˆì„
        Dataset<Row> filteredDf = nullRemovedResultDf.select(
            Arrays.stream(RetColumns)
                .map(functions::col)  // String ë°°ì—´ì„ Column ë°°ì—´ë¡œ ë³€í™˜
                .toArray(Column[]::new)  // Column ë°°ì—´ë¡œ ë³€í™˜
        );


        // Step 7: Calculate covariance (assuming covCalculate is a method defined elsewhere)
        Dataset<Row> covCalculatedDataset = covCalculate(filteredDf);

        // Step 8: Calculate annual returns
        Map<String, Column> aggregatedColumns = tickers.stream()
                .collect(Collectors.toMap(
                        ticker -> "annual_ret_" + ticker,  // Key: annual return column name
                        ticker -> functions.avg("daily_ret_" + ticker)  // Value: average of daily returns
                ));

        // aggregatedColumnsì—ì„œ aliasê°€ ì ìš©ëœ Column ë°°ì—´ ìƒì„±
        Column[] aggColumns = aggregatedColumns.entrySet().stream()
                .map(entry -> entry.getValue().alias(entry.getKey()))
                .toArray(Column[]::new);



        Dataset<Row> meanReturn = calculateAnnualReturn(nullRemovedResultDf);



        log.info(" ì—¬ê¸°ê¹Œì§„ì™”ë‹¤: " + tickers);
        
        resultDf.show();
        log.info(" ì—¬ê¸°ê¹Œì§„ì™”ë‹¤1");

        nullRemovedResultDf.show();
        log.info(" ì—¬ê¸°ê¹Œì§„ì™”ë‹¤2");

        nullRemovedResultDf.show();
        log.info(" ì—¬ê¸°ê¹Œì§„ì™”ë‹¤3");    

        covCalculatedDataset.show();
        log.info(" ì—¬ê¸°ê¹Œì§„ì™”ë‹¤4");    
         // âœ… ëª¬í…Œì¹´ë¥¼ë¡œ ì‹œë®¬ë ˆì´ì…˜ ì‹¤í–‰
        Map<String, List<?>> calculated_result = calculatePortfolioMetrics(meanReturn, covCalculatedDataset, 20000);

        // âœ… ê·¸ë˜í”„ ìƒì„±
        BufferedImage chartImage = generateChart(calculated_result.get("portRet"), calculated_result.get("portRisk"));
        
        // âœ… Base64 ì¸ì½”ë”©í•˜ì—¬ ë°˜í™˜
        String[] columnNames = pivotedDf.columns();
        for (String columnName : columnNames) {
            System.out.println(columnName);  // ì»¬ëŸ¼ëª… ì¶œë ¥
        }
        return encodeImageToBase64(chartImage);
    }

    // ğŸ“Œ XChartë¥¼ ì´ìš©í•´ ê·¸ë˜í”„ ìƒì„±
    private BufferedImage generateChart(List returns, List risks) {
        XYChart chart = new XYChartBuilder().width(800).height(600).title("Monte Carlo Simulation")
                .xAxisTitle("Risk").yAxisTitle("Expected Return").build();

        chart.addSeries("Simulations", risks, returns);
        return BitmapEncoder.getBufferedImage(chart);
    }

    // ğŸ“Œ Base64 ì¸ì½”ë”©
    private String encodeImageToBase64(BufferedImage image) {
        try (ByteArrayOutputStream outputStream = new ByteArrayOutputStream()) {
            ImageIO.write(image, "png", outputStream);
            byte[] imageBytes = outputStream.toByteArray();
            return Base64.getEncoder().encodeToString(imageBytes);
        } catch (Exception e) {
            throw new RuntimeException("ì´ë¯¸ì§€ ì¸ì½”ë”© ì‹¤íŒ¨", e);
        }
    }

    public static Dataset<Row> covCalculate(Dataset<Row> df) {
        // time ì»¬ëŸ¼ ì œì™¸í•œ í‹°ì»¤ ë¦¬ìŠ¤íŠ¸ ì¶”ì¶œ
        List<String> tickers = new ArrayList<>(df.columns().length - 1);
        for (String col : df.columns()) {
            if (!col.equals("time")) {
                tickers.add(col);
            }
        }
    
        List<Row> covList = new ArrayList<>();
        for (String t1 : tickers) {
            for (String t2 : tickers) {
                double covValue = df.stat().cov(t1, t2);
                covList.add(RowFactory.create(t1, t2, covValue));
            }
        }
    
        // ìŠ¤í‚¤ë§ˆ ì •ì˜
        StructType schema = DataTypes.createStructType(new StructField[]{
                DataTypes.createStructField("Ticker1", DataTypes.StringType, false),
                DataTypes.createStructField("Ticker2", DataTypes.StringType, false),
                DataTypes.createStructField("Covariance", DataTypes.DoubleType, false)
        });
    
        // Spark DataFrame ë³€í™˜
        SparkSession spark = df.sparkSession();
        Dataset<Row> covDf = spark.createDataFrame(covList, schema);
    
        // í”¼ë²—í•˜ì—¬ í–‰ë ¬ í˜•íƒœë¡œ ë³€í™˜
        covDf = covDf.groupBy("Ticker1").pivot("Ticker2").agg(functions.first("Covariance"));
    
        // ëª¨ë“  ìˆ˜ì¹˜ ê°’(ê³µë¶„ì‚° ê°’)ì— 365ë¥¼ ê³±í•¨
        for (String ticker : tickers) {
            covDf = covDf.withColumn(ticker, functions.col(ticker).multiply(365));
        }
    
        return covDf;
    }

    public Map<String, List<?>> calculatePortfolioMetrics(Dataset<Row> avgReturns, Dataset<Row> covCalculatedDataset, int simulations) {
        List<Double> portRet = new ArrayList<>();
        List<Double> portRisk = new ArrayList<>();
        List<double[]> portWeights = new ArrayList<>();
        List<Double> sharpeRatio = new ArrayList<>();

        // í‰ê·  ìˆ˜ìµë¥  ë° ê³µë¶„ì‚° ì¶”ì¶œ
        double[] annualRet = extractReturns(avgReturns);
        log.info("annualRet" + annualRet.length);

        double[][] annualCov = extractCovariance(covCalculatedDataset);

        // ì‹œë®¬ë ˆì´ì…˜ì„ í†µí•œ í¬íŠ¸í´ë¦¬ì˜¤ ê³„ì‚°
        Random rand = new Random();

        for (int i = 0; i < simulations; i++) {
            // ëœë¤ ê°€ì¤‘ì¹˜ ìƒì„±
            double[] weights = new double[annualCov.length];
            double weightSum = 0;
            for (int j = 0; j < weights.length; j++) {
                weights[j] = rand.nextDouble();
                weightSum += weights[j];
            }
            // ê°€ì¤‘ì¹˜ ì •ê·œí™”
            for (int j = 0; j < weights.length; j++) {
                weights[j] /= weightSum;
            }

            // í¬íŠ¸í´ë¦¬ì˜¤ ìˆ˜ìµë¥  ê³„ì‚°
            double returns = 0;
            for (int j = 0; j < annualRet.length; j++) {
                returns += weights[j] * annualRet[j];
            }

            // í¬íŠ¸í´ë¦¬ì˜¤ ë¦¬ìŠ¤í¬ ê³„ì‚° (í‘œì¤€í¸ì°¨)
            RealMatrix covarianceMatrix = MatrixUtils.createRealMatrix(annualCov);
            RealVector weightVector = MatrixUtils.createRealVector(weights);
            RealVector weightedCovariance = covarianceMatrix.operate(weightVector);
            double risk = Math.sqrt(weightVector.dotProduct(weightedCovariance));

            // ìƒ¤í”„ ë¹„ìœ¨ ê³„ì‚°
            double sharpe = returns / risk;

            // ê²°ê³¼ ì €ì¥
            portRet.add(returns);
            portRisk.add(risk);
            portWeights.add(weights);
            sharpeRatio.add(sharpe);
        }
        Map<String, List<?>> result = new HashMap<>();
        result.put("portRet", portRet);
        result.put("portRisk", portRisk);
        result.put("portWeights", portWeights);
        result.put("sharpeRatio", sharpeRatio);

        return result;
    }

    private double[] extractReturns(Dataset<Row> avgReturns) {
        // avgReturnsì—ì„œ ì—°ê°„ ìˆ˜ìµë¥  ì¶”ì¶œ (ê°€ì •: ê° rowê°€ í‹°ì»¤ì˜ í‰ê·  ìˆ˜ìµë¥ ì„ ë‹´ê³  ìˆë‹¤ê³  ê°€ì •)
        int numTickers = (int) avgReturns.count();
        double[] returns = new double[numTickers];

        for (int i = 0; i < numTickers; i++) {
            Row row = avgReturns.collectAsList().get(i);
            returns[i] = row.getDouble(1); // assuming the second column contains the return values
        }

        return returns;
    }

    private double[][] extractCovariance(Dataset<Row> covCalculatedDataset) {
        // covCalculatedDatasetì—ì„œ ì—°ê°„ ê³µë¶„ì‚° í–‰ë ¬ ì¶”ì¶œ (ê°€ì •: ê° rowê°€ í‹°ì»¤ë“¤ ê°„ì˜ ê³µë¶„ì‚°ì„ ë‹´ê³  ìˆë‹¤ê³  ê°€ì •)
        int numTickers = (int) covCalculatedDataset.count();
        double[][] covarianceMatrix = new double[numTickers][numTickers];

        for (int i = 0; i < numTickers; i++) {
            Row row = covCalculatedDataset.collectAsList().get(i);
            for (int j = 0; j < numTickers; j++) {
                covarianceMatrix[i][j] = row.getDouble(j + 1); // assuming that columns 1 to N contain the covariance values
            }
        }
        return covarianceMatrix;
    }

    public Dataset<Row> calculateAnnualReturn(Dataset<Row> df) {
        // ì»¬ëŸ¼ëª… ë¦¬ìŠ¤íŠ¸ ê°€ì ¸ì˜¤ê¸°
        // aggregatedColumns: Map<String, Column>ë¥¼ ìƒì„±í•˜ëŠ” ë¶€ë¶„
        Map<String, Column> aggregatedColumns = Arrays.stream(df.columns())
            .collect(Collectors.toMap(
                col -> col.replace("daily_ret", "annual_ret"),  // ì»¬ëŸ¼ëª… ë³€ê²½
                col -> functions.avg(col).multiply(365)           // í‰ê·  ê³„ì‚° í›„ 365 ê³±í•˜ê¸°
            ));

        // Mapì˜ ê°’ì„ Column ë°°ì—´ë¡œ ë³€í™˜ (alias ì ìš©)
        Column[] aggColumns = aggregatedColumns.entrySet().stream()
            .map(entry -> entry.getValue().alias(entry.getKey()))
            .toArray(Column[]::new);

        // agg() ë©”ì„œë“œëŠ” varargs í˜•ì‹ìœ¼ë¡œ ë°›ìœ¼ë¯€ë¡œ, ì²« ë²ˆì§¸ ì›ì†Œì™€ ë‚˜ë¨¸ì§€ ì›ì†Œë“¤ì„ ë¶„ë¦¬í•˜ì—¬ ì „ë‹¬í•©ë‹ˆë‹¤.
        Dataset<Row> annualReturns;
        if (aggColumns.length > 0) {
            annualReturns = df.agg(aggColumns[0], Arrays.copyOfRange(aggColumns, 1, aggColumns.length));
        } else {
            // ì²˜ë¦¬í•  ì»¬ëŸ¼ì´ ì—†ëŠ” ê²½ìš°ì— ëŒ€í•œ ì²˜ë¦¬ (ì˜ˆ: ë¹ˆ ë°ì´í„°í”„ë ˆì„ ë°˜í™˜)
            annualReturns = df;
        }
    
        return annualReturns;
    }

}